#!/usr/bin/env python3

'''
Copyright (C)   2023 Karolina Krzesi≈Ñska <kzokr@dtu.dk>  Danish Cancer Institute & DTU
                2024 Ona Saulianskaite, Danish Cancer Institute

This is an adaptation of the script sourced from: https://gitlab.com/ElofssonLab/afm-benchmark/
Changes made include parsing through all models and respective pkl/json files.
Generating two files, one containing the pDockQ scores per chain and one with more detailed metrics.

We have added the following functions: parse_and_score, process_models, load_data, plus change to main 
function have been made. 
The script supports both AlphaFold2 and AlphaFold3 outputs.
'''

# Imports
from Bio import PDB
import numpy as np
from scipy.optimize import curve_fit
import numpy as np
import argparse
import pickle
import pandas as pd
import json
import os
import logging as log

# retrieve interface pLDDT (predicted Local Distance Difference Test) values from a structural model
def retrieve_IFplddt(structure, chain1, chain2_lst, max_dist):
    ## generate a dict to save IF_res_id
    chain_lst = list(chain1) + chain2_lst #all chains identifiers

    ifplddt = []
    contact_chain_lst = []
    for res1 in structure[0][chain1]:
        for chain2 in chain2_lst:
            count = 0
            for res2 in structure[0][chain2]:
                if res1.has_id('CA') and res2.has_id('CA'):
                   dis = abs(res1['CA']-res2['CA'])
                   ## add criteria to filter out disorder res
                   if dis <= max_dist:
                      ifplddt.append(res1['CA'].get_bfactor())
                      count += 1

                elif res1.has_id('CB') and res2.has_id('CB'):
                   dis = abs(res1['CB']-res2['CB'])
                   if dis <= max_dist:
                      ifplddt.append(res1['CB'].get_bfactor())
                      count += 1
            if count > 0:
              contact_chain_lst.append(chain2)
    contact_chain_lst = sorted(list(set(contact_chain_lst)))

    if len(ifplddt)>0:
       IF_plddt_avg = np.mean(ifplddt)
    else:
       IF_plddt_avg = 0

    return IF_plddt_avg, contact_chain_lst

def retrieve_IFPAEinter(structure, paeMat, contact_lst, max_dist):
    """
    contact_lst:the chain list that have an interface with each chain. For example we have a tetramer with chains A, B, C 
    and D; we know that it has following interfaces A/B A/C B/D C/D, which means that:
    A interacts with chains B and C, B interacts with chains A and D;, C interacts with chains A and D; D interacts with
    chains B and C. This gives us contact list - [['B','C'],['A','D'],['A','D'],['B','C']] of A, B, C, D chains interactors
    respectively.
    """
    chain_lst = [x.id for x in structure[0]]
    seqlen = [len(x) for x in structure[0]]
    ifpae_avg = []
    d=10
    for ch1_idx in range(len(chain_lst)):
      ## extract x axis range from the PAE matrix
      idx = chain_lst.index(chain_lst[ch1_idx])
      ch1_sta=sum(seqlen[:idx])
      ch1_end=ch1_sta+seqlen[idx]
      ifpae_col = []
      ## for each chain that shares an interface with chain1, retrieve the PAE matrix for the specific part.
      for contact_ch in contact_lst[ch1_idx]:
        index = chain_lst.index(contact_ch)
        ch_sta = sum(seqlen[:index])
        ch_end = ch_sta+seqlen[index]
        remain_paeMatrix = paeMat[ch1_sta:ch1_end,ch_sta:ch_end]

        ## get avg PAE values for the interfaces for chain 1
        mat_x = -1
        for res1 in structure[0][chain_lst[ch1_idx]]:
          mat_x += 1
          mat_y = -1
          for res2 in structure[0][contact_ch]:
              mat_y+=1 #index for the current residue in contact_ch
              if res1['CA'] - res2['CA'] <=max_dist:
                 ifpae_col.append(remain_paeMatrix[mat_x,mat_y])
      ## normalize by d(10A) first and then get the average
      if not ifpae_col:
        ifpae_avg.append(0)
      else:
        norm_if_interpae=np.mean(1/(1+(np.array(ifpae_col)/d)**2))
        ifpae_avg.append(norm_if_interpae)

    return ifpae_avg

def calc_pmidockq(ifpae_norm, ifplddt):
    df = pd.DataFrame()
    df['ifpae_norm'] = ifpae_norm
    df['ifplddt'] = ifplddt
    df['prot'] = df.ifpae_norm*df.ifplddt
    fitpopt = [1.31034849e+00, 8.47326239e+01, 7.47157696e-02, 5.01886443e-03] ## from orignal fit function
    df['pmidockq'] = sigmoid(df.prot.values, *fitpopt)

    return df

def sigmoid(x, L ,x0, k, b):
    y = L / (1 + np.exp(-k*(x-x0)))+b
    return (y)

def fit_newscore(df, column):
    testdf = df[df[column]>0]

    colval = testdf[column].values
    dockq = testdf.DockQ.values
    xdata =colval[np.argsort(colval)]
    ydata = dockq[np.argsort(dockq)]

    p0 = [max(ydata), np.median(xdata),1,min(ydata)]
    popt, pcov = curve_fit(sigmoid, xdata, ydata,p0)

    return popt

def load_data(af_version, data_path):
    """Load data from JSON/PKL files based on AlphaFold version."""
    if af_version == "AF2":
        with open(data_path, 'rb') as f:
            data = pickle.load(f)

    elif af_version == "AF3":
        data = {}
        with open(data_path[0], 'r') as f:
            pae_data = json.load(f)
        with open(data_path[1], 'r') as f:
            full_data = json.load(f)

        # combine the data into a single dictionary
        data['predicted_aligned_error'] = np.array(pae_data.get('pae', []))
        data['ranking_confidence'] = full_data.get('ranking_score', None)
        data['ptm'] = full_data.get('ptm', None)
        data['iptm'] = full_data.get('iptm', None)

        for key in ['ranking_confidence', 'ptm', 'iptm']:
            if data[key] is None:
                log.warning(f"'{key}' not found in {data_path}, value set to None.")

    return data

def parse_and_score(str_path, data_path, af_version, distance):
    '''Parse and perform scoring of a given model. 

    str_path - path to the structure file 
    (.cif for AF3, .pdb for AF2)
    data_path - path to json/pkl files
    (for AF3 two files are required)

    '''
    parsers = {"AF2": PDB.PDBParser(), "AF3": PDB.MMCIFParser()}
    parser = parsers.get(af_version)
    
    try:
        structure = parser.get_structure('', str_path)
    except (FileNotFoundError, IOError, ValueError) as e:
        log.error(f"Error opening or parsing structure file '{str_path}': {e}")
        return None

    chains = [chain.id for chain in structure[0]]

    # Define dictionaries
    remain_contact_lst = []
    plddt_lst = []
    
    # retrieve pLDDT from pdb file
    for idx in range(len(chains)):
        chain2_lst = list(set(chains) - set(chains[idx]))
        IF_plddt, contact_lst = retrieve_IFplddt(structure, chains[idx], chain2_lst, distance)
        plddt_lst.append(IF_plddt)
        remain_contact_lst.append(contact_lst)

    # retrieve metrics and PAE
    data = load_data(af_version, data_path)
    avgif_pae = retrieve_IFPAEinter(structure, data['predicted_aligned_error'], remain_contact_lst, distance) 
    ptm_lst = [data['ptm']]
    iptm_lst = [data['iptm']]
    ranking_confidence_lst = [data['ranking_confidence']]

    # calculate pDockQ score
    res = calc_pmidockq(avgif_pae, plddt_lst)

    return chains, res['pmidockq'].tolist(), ptm_lst, iptm_lst, ranking_confidence_lst, avgif_pae, plddt_lst

def process_models(order, af_dir, af_version, models, distance, prefix):
    """Process each model, retrieving scores + parameters"""
    data_list = []

    for i, fname in enumerate(order[:models]):
        if af_version == "AF3":
            data_path = list()
            i = fname.split('_')[-1].split('.')[0]
            str_path = os.path.join(af_dir, f"{prefix}_model_{i}.cif")
            data_path.append(os.path.join(af_dir, fname))
            data_path.append(os.path.join(af_dir, f"{prefix}_summary_confidences_{i}.json"))

        elif af_version == "AF2":
            str_path = os.path.join(af_dir, f"ranked_{i}.pdb")
            data_path = os.path.join(af_dir, f"{prefix}_{fname}.pkl")

        result = parse_and_score(str_path, data_path, af_version, distance)
        if result is None:
            log.error(f"Skipping model {fname} due to errors during parsing or scoring.")
            continue
 
        chains, scores, ptm_scores, iptm_scores, ranking_confidence_scores, avgif_pae, plddt_lst = result        
        
        # construct dictionary per model
        model_data = {'ranked_i': i,
                    'chains': chains,
                    'scores': scores,
                    'ptm_scores': ptm_scores,
                    'iptm_scores': iptm_scores,
                    'ranking_confidence_scores': ranking_confidence_scores,
                    'interface_PAE' : avgif_pae,
                    'interface_pLDDT' : plddt_lst}
        # append to overall dictionary
        data_list.append(model_data)

    return data_list

def main():
    parser = argparse.ArgumentParser(description="Calculate chain-level pDockQ_i.")
    parser.add_argument('af_dir', help="Directory containing AlphaFold results")
    parser.add_argument('-a', '--af-version', dest='af_version', choices=["AF2","AF3"], type=str, required=True, help="Specify the AlphaFold version used (AF2, AF3)")
    parser.add_argument('-r', '--ranking', help="JSON file containing the names of the ranked model; default 'ranking_debug.json' file only applicable for AlphaFold2 output.", default="ranking_debug.json")
    parser.add_argument('-p', '--prefix', help="Suffix preceding the file model name; default 'ranking_debug.json' file only applicable for AlphaFold2 output.", default="result")
    parser.add_argument('-n', '--models', type=int, help="Number of models to be considered in ranking order; default is all models are used.", default=None)
    parser.add_argument('-d', '--distance', type=int, nargs='?', help="Maximum distance of a contact; default distance is 8 A (angstroms).", default=8)

    args = parser.parse_args()

    # basic logging configuration
    log.basicConfig(level=log.INFO, format='%(levelname)s - %(message)s')

    if args.af_version == "AF2":
        # parse the JSON file which includes ranking
        log.info(f"Parsing {args.ranking} file in {args.af_dir}")
        try:
            with open(os.path.join(args.af_dir, args.ranking)) as file:
                order = json.load(file)['order']
        except (IOError, json.JSONDecodeError, KeyError) as e:
            log.error(f"Error reading or parsing {args.ranking}: {e}; exiting...")
            exit(1)

    elif args.af_version == "AF3":
        # parse all json files with the ranking scores
        summary_files = [fname for fname in os.listdir(args.af_dir) if "summary_confidences" in fname]

        if not summary_files:
            # user did not provid the directory with neccessary ALphaFold3 output files with ranking scores
            log.error(f"No AF3 ranking files found in specified directory; exiting...;")
            exit(1)

        args.prefix = "_".join(summary_files[0].split('_')[:-3])

        # dict of json files containing pae values (keys) together with the ranking scores (values)
        summary_files_ranked = dict()
        for file in summary_files:
            model_index = file.split('_')[-1].split('.')[0]
            try:
                with open(os.path.join(args.af_dir, file), 'r') as file:
                    model_data = json.load(file)
                    rank_score = model_data["ranking_score"]
                    summary_files_ranked[f"{args.prefix}_full_data_{model_index}.json"] = rank_score
            except IOError:
                log.error(f"Couldn't open {file} file in the specified input directory; exiting...")
                exit(1)

        # sort dict so that the first json file (model) would have the highest ranking score
        summary_files_ranked = dict(sorted(summary_files_ranked.items(), key=lambda item: item[1], reverse = True))
        order = list(summary_files_ranked.keys())

    # the ranking was found
    log.info(f"Found the following model ranking:")
    for i, fname in enumerate(order):
        log.info(f"{i}\t{fname}")

    # check if provided number of models for analysis does not exceed the maximum number of AlphaFold3 models in the output
    if args.models is None:
        log.info(f"No specific model count requested. All models will be processed.")
        args.models = len(order)
    else:
        if len(order) < args.models:
            log.warning(f"Requested to analyze {args.models} models, but only {len(order)} models are available. Analyzing all available models.")
        else:
            log.info(f"Analyzing the top {args.models} models based on ranking.")

    # process models and store the relevant information
    model_data_list = process_models(order, args.af_dir, args.af_version, args.models, args.distance, args.prefix)

    # write pDockQ scores to a file
    try:
        with open("pDockQ_scores.txt", "w") as output_file:
        # for each model processed
            for model_data in model_data_list:
                i = model_data['ranked_i']
                scores = model_data['scores']
                output_file.write(f"Model ranked_{i} Scores:\n")
                # for each chain report score in output file
                for chain, score in zip(model_data['chains'], scores):
                    output_file.write(f"{chain}: {score:.3f}\n")
                output_file.write("\n")
    except IOError:
        log.warning(f"Failed to create a 'pDockQ_scores.txt' output file")

   # write detailed scores to a CSV file
    try:
        with open("detailed_scores.csv", "w") as output_file:
            output_file.write("Ranked_Model,Chain,pdockq2,Interface_PAE,Interface_plDDT,PTM,iPTM,Ranking_Confidence\n")
        # for each model processed
            for model_data in model_data_list:
                # define variables of interest
                i = model_data['ranked_i']
                chains = model_data['chains']
                scores = model_data['scores']
                ptm_score = model_data['ptm_scores'][0]
                iptm_score = model_data['iptm_scores'][0]
                ranking_confidence = model_data['ranking_confidence_scores'][0]
                if_pae = model_data['interface_PAE']
                if_plddt = model_data['interface_pLDDT']
                # for each chain report all values in outputfile
                for chain, score, ifpae, if_plddt in zip(chains, scores, if_pae, if_plddt):
                    output_file.write(f"ranked_{i},{chain},{score:.3f},{ifpae:.3f},{if_plddt:.3f},{ptm_score:.3f},{iptm_score:.3f},{ranking_confidence:.3f}\n")
    except IOError:
        log.warning(f"Failed to create a 'detailed_scores.csv' output file")

if __name__ == '__main__':
    main()